# Parsing CSV and Compatibility with Py2 and Py3

CSV parsing with Python 2 and 3 differs significantly enough to be a pain.
For example, suppose we want to iterate over the rows and columns of a CSV file and count columns with the character [Ã©](https://en.wiktionary.org/wiki/%C3%A9).
In Python 2, we'd do it like this:

```python
import csv
import sys

magic = u'\u00e9'
reader = csv.reader(sys.stdin, delimiter=b'|', quoting=csv.QUOTE_NONE, escapechar=b'')
counter = 0
for row in reader:
    for col in row:
        if magic in col.decode('utf-8'):
            counter += 1
```

With Python 2's standard library CSV module, the input must be binary.
Therefore, the delimiter, quoting and escape characters must also be binary.
The read CSV columns are also binary.
This is relatively convenient, because sys.stdin is also binary.
However, it means we have to .decode before checking whether our character is there or not.

The above code runs relatively quickly:

```
ash-3.2$ pv sampledata.csv | python read_stdlib2.py
 362MiB 0:01:32 [3.91MiB/s] [====================>] 100%
124
```

With Python 3, we'd have to do this:

```python
import csv
import sys

magic = u'\u00e9'
reader = csv.reader(sys.stdin, delimiter='|', quoting=csv.QUOTE_NONE, escapechar='')
counter = 0
for row in reader:
    for col in row:
        if magic in col:
            counter += 1
```

With Python 3's standard library CSV module, the input must be Unicode.
Therefore, the delimiter, quoting and escape characters, and the output CSV columns are Unicode.
This is why we don't need to .decode like we did with Python2.
Finally, since Python 3's sys.stdin is Unicode, things are rather convenient.
The code also runs much faster than the Python 2 equivalent, which is impressive considering it's also performing UTF-8 decoding.

```
bash-3.2$ pv sampledata.csv | python read_stdlib3.py
 362MiB 0:00:14 [24.5MiB/s] [====================>] 100%
124
```

While this is more convenient, it isn't backward-compatible with Python 2.
People who need their code to run under both Python 2 and 3 can use the [backports_csv](https://pypi.python.org/pypi/backports.csv) module.
The back-ported CSV reader works like Python 3's:

1. Expects a Unicode input stream
2. Expects Unicode delimiters, quoting, and escape characters
3. Outputs Unicode

Since Python 2's standard input is binary, we have to [decode it](https://stackoverflow.com/questions/2737966/how-to-change-the-stdin-encoding-on-python) before we give to the parser:

```python
import codecs
import six


def wrap_stdio(stdin=sys.stdin, stdout=sys.stdout, encoding='utf-8'):
    if six.PY3:
        return stdin, stdout
    return codecs.getreader(encoding)(stdin), codecs.getwriter(encoding)(stdout)

stdin, stdout = wrap_stdio()


if six.PY2:
    from backports import csv
else:
    import csv
```

But now our code Python 2 and 3 cross-compatible, and looks exactly like the Python 3 code above:

```python
magic = u'\u00e9'
reader = csv.reader(stdin, delimiter='|', quoting=csv.QUOTE_NONE, escapechar='')
counter = 0
for row in reader:
    for col in row:
        if magic in col:
            counter += 1
```

Everything is great, but...

```
bash-3.2$ pv sampledata.csv | python read_backports.py
30.1MiB 0:02:07 [ 248KiB/s] [==>                 ]  8% ETA 0:23:20
```

Things are now 100 times slower than the Py3 solution.
For some reason, Python 2 is _really_ slow at decoding bytes into Unicode.
Turns out [I'm not the first](https://nelsonslog.wordpress.com/2015/02/26/python-file-reading-benchmarks/) to bump into this issue.
Here are some interesting conclusions from that link:

> In Python 2, reading lines with Unicode is hella slow. About 7x slower than reading Unicode all at once. And Unicode lines are 70x slower than byte lines!

> In Python 3, reading lines with Unicode is quite fast. About as fast as reading the file all at once. But only if you use the built-in open, not codecs.

Apparently, you can [speed things up a little](https://www.toofishes.net/blog/fast-unicode-decoding-python-27/).
I haven't managed to get this working with the standard I/O streams yet.

# Conclusion

1. Fast
2. Cross-compatible with Python 2 and 3
3. Reads Unicode

If you're working with CSV, pick any two.
